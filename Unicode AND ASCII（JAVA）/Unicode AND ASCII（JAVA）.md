Unicode and all(编码终极总结);


package prototype;


public class SongUnicodeAndAll {
	public static void main(String[] args) {
		char a=65535; //JAVA 使用的Unicode的UCS-2编码方式,它用两个字节来编码字符,两个字节就是16位二进制, 2的16次方等于65536,所以UCS-2最多能编码65536个字符;
		System.out.println(a);//有些字符JVM无法正常显示,所以这里的输出为一个空白;但是如果上式将a赋值为65536则会超出范围报错,这也就是为什么JAVA用16位整型变量char来存储Unicode字符的原因了;
		
		//Unicode码扩展自ASCII字元集:它前128个字符就是ASCII码，之后是扩展码;
		
		//0～32号及第127号(共34个)是控制字符或通讯专用字符：LF（换行）、CR（回车）、FF（换页）等;
		
		char a1=33;   char a2=126;//33～126号(共94个)是字符;
		System.out.println(a1+" --- "+a2); //! --- ~;
		
		char n1=48;   char n2=57; //48～57号为0～9十个阿拉伯数字;
		System.out.println(n1+" --- "+n2); //0 --- 9;
		
		char C1=65;   char C2=90; //65～90号为26个大写英文字母;
		System.out.println(C1+" --- "+C2); //A --- Z;
		
		char c1=97;   char c2=122; //97～122号为26个小写英文字母;
		System.out.println(c1+" --- "+c2); //a --- z;
		
		//其余为一些标点符号、运算符号等!
		//重要信息(数字,大写字母,小写字母的开头编号)形象记忆方式：
		//   48      \ 45
		//   65      \ 67
		//   97      / 89
	}
}


/*
  
编码终极总结:
 
ANSI:
ANSI(American National Standards Institute),最初,ANSI只包括一种字符集--ASCII)不同的国家和地区制定了不同的标准,由此产生了 GB2312、GBK、GB18030、Big5、Shift_JIS等各自的编码标准;
这些使用多个字节来代表一个字符的各种汉字延伸编码方式,称为 ANSI 编码;在简体中文Windows操作系统中,ANSI 编码代表 GBK 编码;在繁体中文Windows操作系统中,ANSI编码代表Big5;
在日文Windows操作系统中，,NSI 编码代表 Shift_JIS编码;不同 ANSI 编码之间互不兼容,当信息在国际间交流时,无法将属于两种语言的文字,存储在同一段 ANSI编码的文本中;

ASCII:
最初,ANSI只包括一种字符集(ASCII-American Standard Code for Information Interchange);ASCII码使用7bit表示一个字符,共128个字符;在计算机的存储单元
中,一个ASCII码值占一个字节(8个二进制位),其最高位(b7)用作奇偶校验位;所谓奇偶校验,是指在代码传送过程中用来检验是否出现错误的一种方法，一般分奇
校验和偶校验两种；奇校验规定：正确的代码一个字节中1的个数必须是奇数,若非奇数,则在最高位b7添1;偶校验规定：正确的代码一个字节中1的个数必须是偶数
,若非偶数,则在最高位b7添1;

第0～32号及第127号(共34个)是控制字符或通讯专用字符，如控制符：LF（换行）、CR（回车）、FF（换页）、DEL（删除）、BEL（振铃）等;
通讯专用字符：SOH（文头）、EOT（文尾）、ACK（确认）等;
第33～126号(共94个)是字符,其中第48～57号为0～9十个阿拉伯数字；65～90号为26个大写英文字母,97～122号为26个小写英文字母,其余为一些标点符号、运
算符号等;


ISO 8859-1:
之后IBM在此基础上做了扩展,用8bit表示1个字符,共256个字符,称为ISO-8859-1字符集;因此向下兼容ASCII;除ASCII收录的字符外,ISO-8859-1收录的字符还包括
西欧语言,希腊语,泰语,阿拉伯语,希伯来语对应的文字符号;欧元符号等出现的比较晚,没有被收录在ISO 8859-1当中;很明显,ISO 8859-1编码表示的字符范围很窄,
例如无法表示中文字符;但是由于ISO-8859-1编码范围使用了单字节内的所有空间，在支持ISO 8859-1的系统中传输和存储其他任何编码的字节流都不会被抛弃;
换言之,把其他任何编码的字节流当作ISO-8859-1编码看待都没有问题;这是个很重要的特性,所以很多情况下（如很多协议传输数据时）都使用ISO 8859-1编码;
我们可以这么说,ASCII编码是一个7位的容器,ISO 8859-1编码是一个8位的容器;有些环境下,将ISO 8859-1写作Latin-1;
latin1(cp1252 West European);


GB2312/BIG5/GBK:
GB2312是汉子的国标码,由中华人民共和国政府制定的,简体汉字编码规范;其表示汉字时是双字节编码,而英文字母和ISO 8859-1一致（兼容ISO 8859-1编码）;与此
对应的还有BIG5,是中华民国政府制定的,繁体汉字的编码规范,一般应用于海外计算机的繁体中文显示;所谓的繁体中文Windows,简体中文Windows,指的就是采用BIG5和GB2312编码格式的操作系统;
这两种编码方式不兼容,如果使用一种编码的文本阅读器来读另一种编码的文本,就会出现乱码。比如在简体中文Windows上读BIG5编码的文件，就是乱码,反之亦然;使用简体浏览器浏览的时候,到了繁体中文网站,
如果不改变码制,也是乱码;
GBK,又称GBK大字符集,简而言之就是将所有亚洲文字的双字节字符,包括简体中文,繁体中文,日语,韩语等,都使用一种格式编码,这样就能够做到在所有的语言平台上面兼容;
而且,目前GB2312,BIG5所包含的汉字数量也不足,比如朱总理的名字一般就打不出;而GBK大字符集包含的汉字数量比GB2312和BIG5多的多了，足够使用;简而言之,GBK编码能够用来同时表示繁体字和简体字,
而GB2312只能表示简体字,因此GBK又是兼容GB2312编码的;
如果已经知道是汉字,则使用GB2312/GBK无疑是最节省的;不过另一方面,值得说明的是,虽然utf编码对汉字使用3个字节,但即使对于汉字网页,
utf编码也会比unicode编码节省,因为网页中包含了很多的英文字符;
从ASCII、GB2312、GBK到GB18030，这些编码方法是向下兼容的，即同一个字符在这些方案中总是有相同的编码，后面的标准支持更多的字符。在这些编码中，英文和中文可以统一地处理。区分中文编码的方法是高字节的最高位不为0;


Unicode:
由于ANSI字符集在不同语言环境下的不统一,导致字符集太多,国际交流中也需要进行字符集转换,带来很大不便,于是出现了unicode字符集;
该字符集使用16bit代表一个字符,可表示65536个字符;Unicode是最统一的编码,可以用来表示所有语言的字符,而且是定长双字节(也有四字节的)编码,
包括英文字母在内;所以可以说它是不兼容ISO 8859-1编码的,也不兼容任何编码;不过,相对于ISO 8859-1中所编码的字符来说,Unicode编码只是在前面增加了一个0字节,
所以Unicode只与ASCII兼容(更准确地说,是与ISO-8859-1兼容);定长编码便于计算机处理(注意GB2312/GBK不是定长编码),而Unicode又可以用来表示所有字符,所以在很多软件内部是使用Unicode编码来处理的,
比如java;为了在网络上传输unicode字符,Unicode可以有多种编码方式,如UTF-16, UTF-8, UTF-32等;

unicode的第一个版本是用两个字节(16bit)来表示所有字符,实际上这么说容易让人产生歧义,我们总觉得两个字节就代表保存在计算机中时是两个字节.于是任何字符如果用unicode表示的话保存下来都占两个字节;
其实这种说法是错误的;Unicode涉及到两个步骤,首先是定义一个规范,给所有的字符指定一个唯一对应的数字,这完全是数学问题,可以跟计算机没半毛钱关系.第二步才是怎么把字符对应的数字保存在计算机中,这才涉及到实际在计算机中占多少字节空间;
所以我们也可以这样理解,Unicode是用0至65535之间的数字来表示所有字符,其中0至127这128个数字表示的字符仍然跟ASCII完全一样,65536是2的16次方;这是第一步,第二步就是怎么把0至65535这些数字转化成01串保存到计算机中,
这肯定就有不同的保存和传输方式了,于是出现了UTF(unicode transformation format),有UTF-8,UTF-16;

注意:myeclipse的默认中文字符集是OS的字符集,windows下是GBK,那么如果改为Unicode(UTF-8),在读取txt文件中的中文时就会出现乱码,需要显示的转换;


UCS:
Unicode的学名是"Universal Multiple-Octet Coded Character Set"，简称为UCS;UCS可以看作是"Unicode Character Set"的缩写;它有两种格式：UCS-2和
UCS-4;顾名思义，UCS-2就是用两个字节编码，UCS-4就是用4个字节（实际上只用了31位，最高位必须为0）编码；UCS字符集为每个字符分配了一个位置，通常用“
U”再加上某个字符在UCS中位置的16进制数作为这个字符的UCS表示，例如“U+0041”表示字符“A”。UCS字符U+0000到U+00FF与ISO-8859-1完全一致；UCS-2
是两个字节的等宽编码，因为只是使用了两个字节的编码空间，所以只能对BMP中的字符做编码；UTF-16是变长编码，用两个字节对BMP内的字符编码，用4个字节对超
出BMP范围的辅助平面内的字符作编码；UTF-16是UCS-2的超集，UTF-16编码的两字节编码方式完全和UCS-2相同，也就是说在BMP的框架内UCS-2完全等同与UTF-16。
实际情况当中常常把UTF-16当作UCS-2的别名;
ucs-2对应utf-16,ucs-4对应UTF-32.UTF-8是没有对应的UCS;
(在传统的二进制数字概念中,1 byte(字节)=8 bit(位);大多数因特网标准使用八位组(octet)这个术语而不是使用字节来表示8位的量,1 octet = 8 bit);


BMP(基本多语言范围 BMP-Basic Multilingual Plane):
UCS-4中,高两个字节为0的码位被称作BMP;将UCS-4的BMP去掉前面的两个零字节就得到了UCS-2;同样UTF-16在BMP的框架内UCS-2完全相等;


UTF:
事实证明,对可以用ASCII表示的字符使用UNICODE并不高效,因为UNICODE比ASCII占用大一倍的空间,而对ASCII来说高字节的0对他毫无用处;为了解决这个问题,就出现了一些中间格式的字符集,
他们被称为通用转换格式,即UTF(Universal Transformation Format);UTF-8,UTF-16, 以及 UTF-32(UTF-32就是把所有的字符都用32bit也就是4个字节来表示,对应ucs-4);
UTF-8是一种变长编码它需要用2个字节编码那些用扩展ASCII字符集只需1个字节的字符（ISO）;
所以,ISO Latin-1 是UNICODE的子集,但不是UTF-8的子集;考虑到Unicode编码不兼容ISO 8859-1编码(但是兼容ASCII:对于单字节的符号,字节的第一位设为0,后面7位为这个符号的unicode码;因此对于英语字母,UTF-8编码和ASCII码是相同的),
而且容易占用更多的空间：因为对于英文字母,Unicode也需要两个字节来表示,所以Unicode不便于传输和存储;因此而产生了UTF编码;


UTF-16 : 标准的Unicode称为UTF-16(UCS-2);这种编码方式大部分字符(BMP的框架内)都以固定长度的字节 (2字节) 储存，所以与ASCII码不兼容;

UTF-8 : 为了双字节的unicode可在单字节系统正确传输,出现了UTF-8;通过UTF-8编码的字节长短不同,0-127范围内的字符被编成1个字节,0080-07ff的字符被编成2个字节,
0800-ffff的字符被编成3个字节;

UTF-8和UTF-16的优劣很容易就看出来了;如果全部英文或英文与其他文字混合,但英文占绝大部分,用UTF-8就比UTF-16节省了很多空间;而如果全部是中文这样类似的字符或者混合字符中中文占绝大多数.UTF-16就占优势了,可以节省很多空间;

在文件的开头几个字节就是区分它们的标志(BOM,Byte Order Mark);
EF BB BF 表示UTF-8;
FE FF 表示UTF-16;


Little endian和Big endian:
Unicode码可以采用UCS-2格式直接存储;以汉字”严“为例,Unicode码是4E25,需要用两个字节存储,一个字节是4E,另一个字节是25;存储的时候,4E在前,25在后,就是Big endian方式;25在前,4E在后,就是Little endian方式;
Unicode：编码是四个字节“FF FE 25 4E”,其中“FF FE”表明是小头方式存储,真正的编码是4E25;
Unicode big endian：编码是四个字节“FE FF 4E 25”,其中“FE FF”表明是大头方式存储; 



GBK一个汉字包含两个字节,其中：
            第一个字节                 第二个字节
GBK      |  x81-0xFE（129-254）    |   0x40-0xFE（64-254）

通过这里，可以知道第一个字节的范围是129~254,这个范围的数,其最高位都是1,而以int类型解释时,最高位是1就意味着这是一个负数,可以据此判断是否为汉字;

例子:编写一个截取字符串的函数,输入为一个字符串和字节数,输出为按字节截取的字符串,但要保证汉字不被截取半个, * 如"我ABC",4,应该截取"我AB",
输入"我ABC汉DEF",6,应该输出"我ABC",而不是"我ABC+汉的半个";

  
public class Test  
{  
    public static void main(String[] args) throws Exception{  
        String str = "我a爱中华abc我爱传智def";  
        int num = trimGBK(str.getBytes("GBK"),6);  
        System.out.println(str.substring(0,num) );  
    }  
      
    public static int  trimGBK(byte[] buf,int n){  
        int num = 0;  
        boolean bChineseFirstHalf = false;  
        for(int i=0;i<n;i++)  
        {  
            if(buf[i]<0 && !bChineseFirstHalf){  
                bChineseFirstHalf = true;  
            }else{  
                num++;  
                bChineseFirstHalf = false;                
            }  
        }  
        return num;  
    }  
      
}  


终极补充:

字符集和字符编码;

什么是字符集?
我们在计算机屏幕上看到的是实体化的文字,而在计算机存储介质中存放的实际是二进制的比特流;
那 么在这两者之间的转换规则就需要一个统一的标准,于是为了实现转换标准,各种字符集标准就出现了;
简单的说字符集就规定了某个文字对应的二进制数字存放方式(编码)和某串二进制数值代表了哪个文字(解码)的转换关系;
那么为什么会有那么多字符集标准呢？这个问题实际非常容易回答;问问自己为什么我们的插头拿到英国就不能用了呢？
很多规范和标准在最初制定时并不会意识到这将会是以后全球普适的准则,或者处于组织本身利益就想从本质上区 别于现有标准;于是,就产生了那么多具有相同效果但又不相互兼容的标准了;

字符集只是一个规则集合的名字,对应到真实生活中,字符集就是某种语言;例如：英语,汉语,日语;
对于一个字符集来说要正确编码转码一个字符需要三个关键元素：字库表(character repertoire)、编码字符集(coded character set)、字符编码(character encoding form);

字库表,一个相当于所有可读或者可显示字符的数据库,字库表决定了整个字符集能够展现表示的所有字符的范围;

编码字符集,即用一个编码值 code point来表示一个字符在字库中的位置;

字符编码,将编码字符集和实际存储数值之间的转换关系;一般来说都会直接将code point的值作为编码后的值直接存储;
例如在ASCII中A在表中排第65位,而编码后A的数值是0100 0001也即十进制的65的二进制转换结果;

字符编码的作用?
字库表和编码字符集看来是必不可少的,那既然字库表中的每一个字符都有一个自己的序号,直接把序号作为存储内容就好了,为什么还要多此一举通过字符编码把序号转换成另外一种存储格式呢？
其实原因也比较容易理解:统一字库表的目的是为了能够涵盖世界上所有的字符,但实际使用过程中会发现真正用的上的字符相对整个字库表来说比例非常低;
例如中文地区的程序几乎不会需要日语字符,而一些英语国家甚至简单的ASCII字库表就能满足基本需求;而如果把每个字符都用字库表中的序号来存储的话,每个字符就需要3个字节(这里以Unicode字库为例),这样对于原本用仅占一个字符的ASCII编码的英语地区国家显然是一个额外成本(存储体积 是原来的三倍);
算的直接一些,同样一块硬盘,用ASCII可以存1500篇文章,而用3字节Unicode序号存储只能存500篇;于是就出现了 UTF-8这样的变长编码;在UTF-8编码中原本只需要一个字节的ASCII字符,仍然只占一个字节;而像中文及日语这样的复杂字符就需要2个到3个字 节来存储;

总结:其实虽然字符编码和编码字符集的概念不同,但是没有本质的区分,也就是说unicode既是编码字符集,也是字符编码,主要由计算机或者软件内部的字符集选取和存储字符时所选择的编码方式决定;只是说虽然字符集可以是Unicode,但是编码方式可以选择其他更节省空间的字符编码(比如UTF-8)来对字符保存(编码)时的二进制代码
进行转换(这样的不同编码字符集之间代码的转换在计算机内部也有一一对应的表,但是要注意的是如果用比如ISO 8859-1的编码方式来存储中文,由于ISO 8859-1的编码字符集和字库表中根本就不对应中文,这样的强制转换会存在信息丢失和错误,那么在解码时是无法得到转换之前的字符代码的),
最后在解码时如果不以utf-8的编码方式来解码,而是以unicode的方式解码,那么很显然之前保存的字符代码是对应UTF-8字库表中的字符的,现在不转换为unicode字符集中的代码就去unicode字库表中查找对应字符,肯定不是编码之前的字符,除非这两个字符集有兼容关系,也就是字符的编码字符集二进制数代码在字库集中对应的字符也是相同的;



*/



